{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5f0c42-bf8d-450f-aa69-6a2ecb1a5ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T12:41:01.745393Z",
     "start_time": "2024-06-26T12:40:22.947435Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sys args (filename | NN filename | SIGNAL_RATE | ch1 ch2 ...):\n",
      " ['Detecting_system.py', '44330-exportGlobus2-new.txt', 'cnn_v14', '10', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch9', 'ch10', 'ch11', 'ch12']\n",
      "\n",
      "#log: Выбран файл 44330-exportGlobus2-new.txt (FILE_ID: 44330)\n",
      "#log: Файл 44330-exportGlobus2-new.txt считан успешно. Tooks - 10.99 s.\n",
      "\n",
      "#log: Для файла FILE_ID: 44330 выбраны каналы: ['ch1', 'ch2']\n",
      "\n",
      "#log: Начата предварительная обработка данных.\n",
      "|.............|\n",
      "#log: Предварительная обработка и фильтрация выполнена успешно. Tooks - 553.18 s.\n",
      "==========================================\n",
      "#log: Количество найденных фрагментов: 1275\n",
      "==========================================\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "#log: Обработка завершена. Tooks - 478.71999999999997 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 8\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 8\n",
      "Филаментов: 8 (средняя оценка филаментов: 0.85)\n",
      "Не филаментов: 1267\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 8\n",
      "Филаментов: 8 (средняя оценка филаментов: 0.85)\n",
      "Не филаментов: 1267\n",
      "#log: Результаты сохранены. Tooks - 1.78 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "#log: Обработка завершена. Tooks - 427.86 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 11\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 11\n",
      "Филаментов: 11 (средняя оценка филаментов: 0.86)\n",
      "Не филаментов: 1264\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 11\n",
      "Филаментов: 11 (средняя оценка филаментов: 0.86)\n",
      "Не филаментов: 1264\n",
      "#log: Результаты сохранены. Tooks - 1.95 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "\n",
      "#log: Для файла FILE_ID: 44330 выбраны каналы: ['ch3', 'ch4']\n",
      "\n",
      "#log: Начата предварительная обработка данных.\n",
      "|..............|\n",
      "#log: Предварительная обработка и фильтрация выполнена успешно. Tooks - 452.85 s.\n",
      "==========================================\n",
      "#log: Количество найденных фрагментов: 928\n",
      "==========================================\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "#log: Обработка завершена. Tooks - 273.24 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 3\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 3\n",
      "Филаментов: 3 (средняя оценка филаментов: 0.7)\n",
      "Не филаментов: 925\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 3\n",
      "Филаментов: 3 (средняя оценка филаментов: 0.7)\n",
      "Не филаментов: 925\n",
      "#log: Результаты сохранены. Tooks - 1.36 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "#log: Обработка завершена. Tooks - 276.24 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 2\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 2\n",
      "Филаментов: 2 (средняя оценка филаментов: 0.58)\n",
      "Не филаментов: 926\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 2\n",
      "Филаментов: 2 (средняя оценка филаментов: 0.58)\n",
      "Не филаментов: 926\n",
      "#log: Результаты сохранены. Tooks - 1.27 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "\n",
      "#log: Для файла FILE_ID: 44330 выбраны каналы: ['ch5', 'ch6']\n",
      "\n",
      "#log: Начата предварительная обработка данных.\n",
      "|..............|\n",
      "#log: Предварительная обработка и фильтрация выполнена успешно. Tooks - 192.1 s.\n",
      "==========================================\n",
      "#log: Количество найденных фрагментов: 148\n",
      "==========================================\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "#log: Обработка завершена. Tooks - 305.19 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 0\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 0\n",
      "Филаментов: 0 (средняя оценка филаментов: 0.0)\n",
      "Не филаментов: 148\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 0\n",
      "Филаментов: 0 (средняя оценка филаментов: 0.0)\n",
      "Не филаментов: 148\n",
      "#log: Результаты сохранены. Tooks - 0.26 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/stepWARNING:tensorflow:5 out of the last 39 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F900BD5080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "#log: Обработка завершена. Tooks - 306.18 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 0\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 0\n",
      "Филаментов: 0 (средняя оценка филаментов: 0.0)\n",
      "Не филаментов: 148\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 0\n",
      "Филаментов: 0 (средняя оценка филаментов: 0.0)\n",
      "Не филаментов: 148\n",
      "#log: Результаты сохранены. Tooks - 0.27 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "\n",
      "#log: Для файла FILE_ID: 44330 выбраны каналы: ['ch9', 'ch10']\n",
      "\n",
      "#log: Начата предварительная обработка данных.\n",
      "|..............|\n",
      "#log: Предварительная обработка и фильтрация выполнена успешно. Tooks - 530.65 s.\n",
      "==========================================\n",
      "#log: Количество найденных фрагментов: 1188\n",
      "==========================================\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F900B83E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "#log: Обработка завершена. Tooks - 424.84 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 35\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 35\n",
      "Филаментов: 35 (средняя оценка филаментов: 0.94)\n",
      "Не филаментов: 1153\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 35\n",
      "Филаментов: 35 (средняя оценка филаментов: 0.94)\n",
      "Не филаментов: 1153\n",
      "#log: Результаты сохранены. Tooks - 3.57 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "#log: Обработка завершена. Tooks - 418.86 ms.\n",
      "\n",
      "\n",
      "#log: Обработка завершена. Проведена оценка с границей: 0.75\n",
      "==========================================\n",
      "#log: Количество спрогнозированных филаментов: 25\n",
      "==========================================\n",
      "\n",
      "#log: Сохранение результатов.\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 25\n",
      "Филаментов: 25 (средняя оценка филаментов: 0.92)\n",
      "Не филаментов: 1163\n",
      "|..........|\n",
      "Количество сохранённых фрагментов: 25\n",
      "Филаментов: 25 (средняя оценка филаментов: 0.92)\n",
      "Не филаментов: 1163\n",
      "#log: Результаты сохранены. Tooks - 2.99 s. Файлы:\n",
      "data_csv/result_data/44330-exportGlobus2-new_cnn_v14_data.csv\n",
      "\n",
      "\n",
      "#log: Для файла FILE_ID: 44330 выбраны каналы: ['ch11', 'ch12']\n",
      "\n",
      "#log: Начата предварительная обработка данных.\n",
      "|.........|\n",
      "#log: Предварительная обработка и фильтрация выполнена успешно. Tooks - 106.98 s.\n",
      "==========================================\n",
      "#log: Количество найденных фрагментов: 0\n",
      "==========================================\n",
      "#log: Данные фрагментов нормализованы и подготовлены для нейро-фильтра.\n",
      "#log: Версия фильтра: cnn_v14\n",
      "#log: Запуск фильтра. Прогнозирование:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f.belous\\AppData\\Local\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\Work\\Projects\\Plasma_processing\\Detecting_system.py:149\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (sys\u001b[38;5;241m.\u001b[39mstdin \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39misatty()):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# get args from CL\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSys args (filename | NN filename | SIGNAL_RATE | ch1 ch2 ...):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sys\u001b[38;5;241m.\u001b[39margv)\n\u001b[1;32m--> 149\u001b[0m     init_proc(sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mint\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m3\u001b[39m]), sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m4\u001b[39m:])\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgram is supposed to run out from command line.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Work\\Projects\\Plasma_processing\\Detecting_system.py:142\u001b[0m, in \u001b[0;36minit_proc\u001b[1;34m(filename, nn_name, SIGNAL_RATE, input_channels)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[0;32m    140\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(selected_data[ch][(selected_data\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf) \u001b[38;5;241m&\u001b[39m (selected_data\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf)]))\n\u001b[1;32m--> 142\u001b[0m detect_function(x, y, filename, meta, channels, proj_path, data_path, nn_name, SIGNAL_RATE)\n\u001b[0;32m    143\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32m~\\Work\\Projects\\Plasma_processing\\Detecting_system.py:60\u001b[0m, in \u001b[0;36mdetect_function\u001b[1;34m(data_t, data_ch, file_name, signal_meta, signal_channels, path_to_proj, path_to_csv, nn_filename, SIGNAL_RATE)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(signal_channels)):\n\u001b[0;32m     58\u001b[0m     name_filter \u001b[38;5;241m=\u001b[39m nn_filename\n\u001b[1;32m---> 60\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m filtering_function([fragments[\u001b[38;5;241m0\u001b[39m], fragments[ch_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]], name_filter, path_to_proj)\n\u001b[0;32m     62\u001b[0m     edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.75\u001b[39m\n\u001b[0;32m     64\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m predictions \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m edge\n",
      "File \u001b[1;32m~\\Work\\Projects\\Plasma_processing\\Detecting_system.py:36\u001b[0m, in \u001b[0;36mfiltering_function\u001b[1;34m(fragments, name_filter, path_to_proj)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#log: Запуск фильтра. Прогнозирование:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 36\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(class_scores_processing, \u001b[38;5;241m1\u001b[39m, neuro_filter\u001b[38;5;241m.\u001b[39mpredict(fragments_smooth, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# log\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#log: Обработка завершена. Tooks - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\progbar.py:119\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    116\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     numdigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mlog10(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    120\u001b[0m     bar \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(numdigits) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m (current, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[0;32m    121\u001b[0m     bar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[1m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\x1b\u001b[39;00m\u001b[38;5;124m[0m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "# args from CL: filename, nn_name, SIGNAL_RATE, ch1, ch2\n",
    "# ch1 ch2 ch3 ch4 ch5 ch6 ch9 ch10 ch11 ch12\n",
    "%run Detecting_system.py 44330-exportGlobus2-new.txt cnn_v14 10 ch1 ch2 ch3 ch4 ch5 ch6 ch9 ch10 ch11 ch12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3958a0-23dc-4cc6-9341-9183e35ce59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
